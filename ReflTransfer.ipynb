{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The first section is a general introduction to the PGF library and a few helpful functions. If you know the basics already, feel free to skip to [Part II](#Part-II:-Manipulating-syntax-trees).*\n",
    "\n",
    "You should have the file `MiniLang.pgf` in the same directory where you run this notebook.\n",
    "\n",
    "First, we import the PGF library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the PGF library, we read the .pgf file and store it in a variable `gr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pgf.PGF"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = pgf.readPGF(\"MiniLang.pgf\")\n",
    "type(gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the concrete syntaxes in `gr.languages`, which is a dictionary. English is found in `MiniLangEng`.\n",
    "\n",
    "Why? Because we wrote in the GF grammar `concrete MiniLangEng of MiniLang`. Thus the concrete syntax is named `MiniLangEng` also in the PGF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = gr.languages[\"MiniLangEng\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the concrete syntax `eng`, we can e.g. *parse* a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UttS (UsePresCl PPos (PredVP (DetCN the_Det (UseN star_N)) (UseAP (PositA big_A))))\n"
     ]
    }
   ],
   "source": [
    "i = eng.parse(\"the star is big\")\n",
    "prob,expr = next(i)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I see me'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.linearize(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we *embed* the grammar, so that we can use the GF functions (`DetCN` etc.) as Python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'MiniLang'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.embed(\"MiniLang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MiniLang import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import * from MiniLang just so that we don't need to write `MiniLang.DetCN(MiniLang.the_Det, MiniLang.UseN(MiniLang.star_N))`.\n",
    "\n",
    "Check out all the functions in scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdjCN',\n",
       " 'AdvVP',\n",
       " 'ComplV2',\n",
       " 'CoordS',\n",
       " 'DetCN',\n",
       " 'In',\n",
       " 'MassNP',\n",
       " 'Out',\n",
       " 'PNeg',\n",
       " 'PPos',\n",
       " 'PositA',\n",
       " 'PredVP',\n",
       " 'PrepNP',\n",
       " 'ReflV2',\n",
       " 'UseAP',\n",
       " 'UseN',\n",
       " 'UsePN',\n",
       " 'UsePresCl',\n",
       " 'UsePron',\n",
       " 'UseV',\n",
       " 'UttNP',\n",
       " 'UttS',\n",
       " '_',\n",
       " '_14',\n",
       " '_16',\n",
       " '_18',\n",
       " '_20',\n",
       " '_23',\n",
       " '_24',\n",
       " '_25',\n",
       " '_37',\n",
       " '_38',\n",
       " '_61',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i10',\n",
       " '_i11',\n",
       " '_i12',\n",
       " '_i13',\n",
       " '_i14',\n",
       " '_i15',\n",
       " '_i16',\n",
       " '_i17',\n",
       " '_i18',\n",
       " '_i19',\n",
       " '_i2',\n",
       " '_i20',\n",
       " '_i21',\n",
       " '_i22',\n",
       " '_i23',\n",
       " '_i24',\n",
       " '_i25',\n",
       " '_i26',\n",
       " '_i27',\n",
       " '_i28',\n",
       " '_i29',\n",
       " '_i3',\n",
       " '_i30',\n",
       " '_i31',\n",
       " '_i32',\n",
       " '_i33',\n",
       " '_i34',\n",
       " '_i35',\n",
       " '_i36',\n",
       " '_i37',\n",
       " '_i38',\n",
       " '_i39',\n",
       " '_i4',\n",
       " '_i40',\n",
       " '_i41',\n",
       " '_i42',\n",
       " '_i43',\n",
       " '_i44',\n",
       " '_i45',\n",
       " '_i46',\n",
       " '_i47',\n",
       " '_i48',\n",
       " '_i49',\n",
       " '_i5',\n",
       " '_i50',\n",
       " '_i51',\n",
       " '_i52',\n",
       " '_i53',\n",
       " '_i54',\n",
       " '_i55',\n",
       " '_i56',\n",
       " '_i57',\n",
       " '_i58',\n",
       " '_i59',\n",
       " '_i6',\n",
       " '_i60',\n",
       " '_i61',\n",
       " '_i62',\n",
       " '_i63',\n",
       " '_i7',\n",
       " '_i8',\n",
       " '_i9',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " 'aPl_Det',\n",
       " 'a_Det',\n",
       " 'allnames',\n",
       " 'already_Adv',\n",
       " 'and_Conj',\n",
       " 'animal_N',\n",
       " 'apple_N',\n",
       " 'baby_N',\n",
       " 'bad_A',\n",
       " 'beer_N',\n",
       " 'bigStar',\n",
       " 'big_A',\n",
       " 'bigstar',\n",
       " 'bike_N',\n",
       " 'bird_N',\n",
       " 'black_A',\n",
       " 'blood_N',\n",
       " 'blue_A',\n",
       " 'boat_N',\n",
       " 'book_N',\n",
       " 'boy_N',\n",
       " 'bread_N',\n",
       " 'break_V2',\n",
       " 'buy_V2',\n",
       " 'car_N',\n",
       " 'cat_N',\n",
       " 'child_N',\n",
       " 'children',\n",
       " 'childrensNames',\n",
       " 'city_N',\n",
       " 'clean_A',\n",
       " 'clever_A',\n",
       " 'cloud_N',\n",
       " 'cold_A',\n",
       " 'come_V',\n",
       " 'computer_N',\n",
       " 'cow_N',\n",
       " 'dirty_A',\n",
       " 'dog_N',\n",
       " 'drink_V2',\n",
       " 'e',\n",
       " 'eat_V2',\n",
       " 'eng',\n",
       " 'every_Det',\n",
       " 'exit',\n",
       " 'find_V2',\n",
       " 'fire_N',\n",
       " 'fish_N',\n",
       " 'flower_N',\n",
       " 'friend_N',\n",
       " 'fun',\n",
       " 'getName',\n",
       " 'get_ipython',\n",
       " 'girl_N',\n",
       " 'go_V',\n",
       " 'good_A',\n",
       " 'gr',\n",
       " 'grammar_N',\n",
       " 'green_A',\n",
       " 'he_Pron',\n",
       " 'heavy_A',\n",
       " 'horse_N',\n",
       " 'hot_A',\n",
       " 'house_N',\n",
       " 'i',\n",
       " 'i_Pron',\n",
       " 'in_Prep',\n",
       " 'john_PN',\n",
       " 'jump_V',\n",
       " 'kill_V2',\n",
       " 'language_N',\n",
       " 'live_V',\n",
       " 'love_V2',\n",
       " 'man_N',\n",
       " 'milk_N',\n",
       " 'music_N',\n",
       " 'name',\n",
       " 'new_A',\n",
       " 'now_Adv',\n",
       " 'old_A',\n",
       " 'on_Prep',\n",
       " 'or_Conj',\n",
       " 'p',\n",
       " 'paris_PN',\n",
       " 'pgf',\n",
       " 'play_V',\n",
       " 'quit',\n",
       " 'read_V2',\n",
       " 'ready_A',\n",
       " 'red_A',\n",
       " 'river_N',\n",
       " 'run_V',\n",
       " 'sea_N',\n",
       " 'see_V2',\n",
       " 'she_Pron',\n",
       " 'ship_N',\n",
       " 'sleep_V',\n",
       " 'small_A',\n",
       " 'star_N',\n",
       " 'swim_V',\n",
       " 'teach_V2',\n",
       " 'thePl_Det',\n",
       " 'the_Det',\n",
       " 'they_Pron',\n",
       " 'topName',\n",
       " 'train_N',\n",
       " 'travel_V',\n",
       " 'tree_N',\n",
       " 'understand_V2',\n",
       " 'useprescl',\n",
       " 'wait_V2',\n",
       " 'walk_V',\n",
       " 'warm_A',\n",
       " 'water_N',\n",
       " 'we_Pron',\n",
       " 'white_A',\n",
       " 'wine_N',\n",
       " 'with_Prep',\n",
       " 'woman_N',\n",
       " 'yellow_A',\n",
       " 'youPl_Pron',\n",
       " 'youSg_Pron',\n",
       " 'young_A']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can form trees out of the GF constructors, in Python with Python's syntax for function application. Compare the two syntaxes:\n",
    "\n",
    "\n",
    "* GF\n",
    "```\n",
    "DetCN the_Det (UseN star_N)\n",
    "```\n",
    "\n",
    "* Python\n",
    "```\n",
    "DetCN(the_Det, UseN(star_N))\n",
    "```\n",
    "\n",
    "We can create a full sentence like this and call it `bigStar`. Its type is `pgf.Expr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pgf.Expr"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigStar = UsePresCl(PPos, PredVP(DetCN(the_Det, UseN(star_N)), UseAP(PositA(big_A))))\n",
    "type(bigStar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we print `bigStar`, we'll see how it looks like with GF's syntax for function application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UsePresCl PPos (PredVP (DetCN the_Det (UseN star_N)) (UseAP (PositA big_A)))\n"
     ]
    }
   ],
   "source": [
    "print(bigStar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also linearise `bigStar` with the concrete syntax `eng`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the star is big'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng.linearize(bigStar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat more interesting function is `unpack`. Let's try it on `bigStar`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('UsePresCl', [<pgf.Expr at 0x10440b8a0>, <pgf.Expr at 0x10440b0a8>])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigStar.unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`unpack` returns a tuple of `(String, [Expr])`, i.e. the name of the constructor and a list of its subtrees. We can further call `unpack` to the subtrees to get their names and subtrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('UsePresCl',\n",
       " [('PPos', []),\n",
       "  ('PredVP', [<pgf.Expr at 0x104406b98>, <pgf.Expr at 0x104268df0>])])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topName, children = bigStar.unpack()\n",
    "(topName, [child.unpack() for child in children])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you think it would be fun, you can try to write one function that returns the names of all the constructors from an expression, all in one list. Use `unpack`, not the string representation of the tree. (Hint: you can search for tree traversal algorithms.) \n",
    "\n",
    "If you don't think this sounds like fun, skip to the next section! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[UsePresCl, PPos, PredVP, DetCN, the_Det, UseN, star_N, UseAP, PositA, big_A] in any order'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def allnames(expr):\n",
    "    # Write an actual implementation here\n",
    "    return \"[UsePresCl, PPos, PredVP, DetCN, the_Det, UseN, star_N, UseAP, PositA, big_A] in any order\"\n",
    "        \n",
    "allnames(bigStar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Manipulating syntax trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get to the part where we do some syntactic transfer on GF trees.\n",
    "\n",
    "The GF grammar generates sentences such as *I like me*, *you see you*, *John asks John*.  \n",
    "We will transform them into reflexive versions: *I like myself*, *you see yourself*, *John asks himself*.\n",
    "\n",
    "The usage of the function should look like this:\n",
    "\n",
    "```python\n",
    "> translate(\"I see you\")\n",
    "I see you  \n",
    "\n",
    "> translate(\"I see me\")\n",
    "I see myself\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for a sentence to be transformed, its subject and object must be the same. Thus we need to pattern match at the `Cl` level: only then we have access to both subject and object. So this is the smallest tree we can look at:\n",
    "\n",
    "```haskell\n",
    "PredVP (UsePron i_Pron) (ComplV2 see_V2 (UsePron i_Pron)))\n",
    "```\n",
    "\n",
    "Let's define a function that looks at a `Cl`. We know already how to use `unpack`, now all we need to do is to check the names of the subtrees and decide if we go further with the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toReflexiveCl(cl):\n",
    "    '''Analysing Cl'''\n",
    "    clFunName, clChildren = cl.unpack()\n",
    "    if clFunName==\"PredVP\":\n",
    "        # When we match a function name, \n",
    "        # we know which and how many arguments it has.\n",
    "        subj = clChildren[0]\n",
    "        vp = clChildren[1]\n",
    "        vpFunName, vpChildren = vp.unpack()\n",
    "        if vpFunName==\"ComplV2\": # Only consider VPs that have an object\n",
    "            v2 = vpChildren[0]\n",
    "            obj = vpChildren[1]\n",
    "            if subj==obj:\n",
    "                reflVP = ReflV2(v2) # Remember: ReflV2 is now a Python function, thanks to gr.embed(MiniLang)\n",
    "                return PredVP(subj, reflVP) # Old subject, new reflexive VP\n",
    "    return cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function would now work if we apply it to a tree of type `Cl`. But when we parse a sentence, we don't get a `Cl` but an `Utt`; that's because `Utt` is the start category of the grammar. Thus we need more functions to transform `S` and `Utt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toReflexiveS(sent):\n",
    "    '''Analysing S'''\n",
    "    sFunName, sChildren = sent.unpack()\n",
    "    if sFunName==\"UsePresCl\":\n",
    "        pol = sChildren[0] # polarity\n",
    "        cl = sChildren[1] # clause\n",
    "        return UsePresCl(pol, toReflexiveCl(cl))\n",
    "    elif sFunName==\"CoordS\":\n",
    "        conj = sChildren[0]\n",
    "        s1 = sChildren[1]\n",
    "        s2 = sChildren[2]\n",
    "        return CoordS(conj, toReflexiveS(s1), toReflexiveS(s2))\n",
    "    else: return sent\n",
    "        \n",
    "def toReflexive(utt):\n",
    "    '''Top layer: analysing the start category Utt.'''\n",
    "    uttFunName, uttChildren = utt.unpack()\n",
    "    if uttFunName==\"UttS\": # there chould be a reflexive in the child of type S\n",
    "        s = uttChildren[0]\n",
    "        return UttS(toReflexiveS(s))\n",
    "    else: return utt # The other constructor is UttNP, and it cannot contain a reflexive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I see you\n",
      "I see myself\n"
     ]
    }
   ],
   "source": [
    "def translate(str):\n",
    "    i = eng.parse(str)\n",
    "    prob,expr = next(i)\n",
    "    print(eng.linearize(toReflexive(expr)))\n",
    "    \n",
    "translate(\"I see you\")\n",
    "translate(\"I see me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
